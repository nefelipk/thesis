\documentclass[12pt,a4paper]{report}
\usepackage[english]{babel}
\usepackage[utf8]{inputenc}

\usepackage[colorlinks]{hyperref}
\usepackage[colorinlistoftodos]{todonotes}

\usepackage[autostyle]{csquotes}
\usepackage[nottoc]{tocbibind}
\usepackage{indentfirst}

\usepackage[normalem]{ulem}
\usepackage{amsmath}

\newcommand{\example}{\enquote}
\newcommand{\term}{\textit}
\newcommand{\acronym}{\MakeUppercase}
\newcommand{\itfrac}[2]{\frac{\textit{#1}}{\textit{#2}}}

\begin{document}
	{
		\hypersetup{linkcolor=black}
		\tableofcontents
	}
	
	\chapter{Introduction}
	\label{sec:intro}
	
	During the last years the focus of research for robotic applications evolved 
	from well structured indoor environments to unstructured outdoor environments. 
	With this expansion of interest, it is a crucial prerequisite to reliably 
	classify traversable ground in the environment, especially when it comes to 
	truly autonomous systems. This topic is typically referred to as 
	\term{traversability analysis} or \term{obstacle detection} \cite{Suger}. 
	Failing on this	task can cause great damage or restrict the robots movement 
	unnecessarily.
	\\
	
	So, \term{traversability} is the generic capability of a robotic ground 
	vehicle to navigate within environments of varying complexity, while ensuring 
	safety in terms of collisions or reaching unrecoverable states and achieving 
	goals in an optimal mode of operation \cite{Papadakis}. Occasionally other 
	terms such as \term{mobility} \cite{Lalonde}, \term{terrainability}, etc are 
	used to describe the same thing.
	\\
		
	There is the probability that previously learned behavior may not be relevant, 
	because the visual appearance and \term{traversability} of roads may have 
	changed due to various reasons \cite{Wigness}. That is probably why 
	\term{geometry-based} analysis is the direction followed by the majority of 
	\term{traversability analysis} methodologies \cite{Papadakis}.
	\\
	
	So, if autonomous mobile robots are to become more generally useful, they must 
	be able to adapt to new environments and learn from experience. To do so, they 
	need a way to store pertinent information about the environment, recall the 
	information at appropriate times, and reliably match stored information with 
	newly-sensed data. They also must be able to modify the stored information to 
	account for systematic changes in the environment \cite{Shneier}.
	\\
	
	In this thesis, we will tackle how an autonomous robot can improve its 
	\term{traversability} estimation method in natural environments, meaning not 
	only on bare ground-like environment, but also on terrain containing vegetation. 
	We will determine how to introduce a learning capability to the robot that will 
	enable it to decide for itself the \term{traversability} of the terrain around 
	it, based on input from its sensors and its experience of traveling over similar 
	terrain in the past. We would also like our robot to plan further ahead	and 
	avoid entering traps that prevent it from reaching its goal.
	\\
	
	\sout{That means, for example, that it should be able to traverse grass but avoid 
	rocks hidden in it.}
	
	\chapter{Background}
	\label{sec:bg}
	
	\section{A few words}
	\label{sec:bg:intro}
	
	In order to have an autonomous robot improve its \term{traversability} 
	estimation we will need to address each sub-problem individually:
	
	\begin{enumerate}
		\item \term{Traversability} estimation algorithms that can be improved from 
		experience/examples.
		\item Methods for collecting the data needed by the algorithm above, from 
		the sensory input that is available to the robot. (The input we have does not 
		directly map to positive/negative decision).
		\item Goals of operation. There might be an explicit goal to achieve or it 
		could be curiosity-driven exploration, meaning the abstract need to learn a 
		new environment.
	\end{enumerate}
	
	We will now present the state of the art in all three areas of research.
	\\
	
	\section{Learning traversability estimation algorithms}
	\label{sec:bg:trav}
	
	In order for an autonomous robot to be able to safely navigate, it is crucial 
	for it to be able to conclude on its own the terrain \term{traversability} 
	around it. Many papers have been published regarding this, and here we present 
	some of the most recent and most influential.
	\\
	
	This line of research starts with Lalonde et al. that segment local three-
	dimensional (\acronym{3d}) \term{point clouds} using a purely geometric 
	approach \cite{Lalonde}, for autonomous robot navigation purposes. A 
	\term{point cloud} is a set of data points in space, generally produced by 
	\acronym{3d} scanners. The approach used is a segmentation in three terrain 
	categories, based on scatter-ness, linear-ness, and surface-ness. That way 
	the authors are able to represent porous volumes such as grass and tree canopy, 
	capture thin objects like wires or tree branches, and capture solid objects 
	like ground surface, rocks or large trunks, respectively.
	\\	
	
	\todo[size={{\scriptsize}}]{Should I not use "someone et al." at all?}
	Later on, Suger et al. proposed a learning approach that uses a two-dimensional 
	(\acronym{2d}) \term{occupancy grid} map, where each cell stores features 
	that provide information from the senors \cite{Suger}. \term{Occupancy grid} 
	maps are \acronym{2d} arrays depicting the robot’s environment with regions 
	classified as empty, occupied or unknown (for more details about those see 
	\cite{Moravec}). In \cite{Suger}, every sell is associated with at least one 
	feature vector that is computed from the \acronym{3d} \term{point clouds} that 
	are mapped to the respective cell. The authors use the features mentioned 
	bellow (mostly geometrical, like in \cite{Lalonde}) to distinguish different 
	types of terrain as well as \term{traversability} constraints of the robot. 
	\begin{enumerate}
		\item[$\bullet$] Maximum height difference and
		\item[$\bullet$] slope 
	\end{enumerate}
	reflect the ground-clearance of the robot as well as the motor power.
	\begin{enumerate}
		\item[$\bullet$] Roughness and
		\item[$\bullet$] remission values (meaning the the reflection or scattering 
		of light by a material) 
	\end{enumerate}
	help to distinguish concrete and vegetation types.
	\\
	
	Wigness et al. proposed another way to learn new behaviors quickly in the 
	field with no or minimal human supervision. They propose a methodology for 
	learning reward functions from human examples via visual perception 
	\cite{Wigness}. This means that the agent learns how to simply assign costs 
	to distinct terrain types, and follows the trajectory with the minimum cost. 
	This approach is more focused than \cite{Suger} in following the optimum path, 
	but less in experimenting with \term{traversability}. It also insists on 
	dynamic environments, while \cite{Suger} interprets the characteristic of 
	\term{traversability} to be static, and further assume that dynamic objects 
	are detected and removed in advance.
	\\
	
	
	A different line of research starts with Pfaff et al. that decided to represent 
	the environment of a mobile robot with \term{elevation maps}, another geometric 
	approach. A \term{digital elevation map} (\acronym{dem}) is also known as 
	\term{2\(\itfrac{1}{2}\)-dimensional representation} of the environment 
	\cite{Pfaff}. It is a \acronym{2d} array of terrain elevation measurements. More 
	concrete, it is a grid that stores in each cell the vertical distance above or 
	below the corresponding surface (additional information about \acronym{dem} can 
	be found in \cite{Kweon}). 
	\par 
	The representation of the environment with \term{elevation maps}, however, can 
	be problematic when a robot has to utilize these maps for navigation. For 
	example, when a mobile robot is located in front of a bridge, the underpass will 
	completely disappeared and the \term{elevation map} will show a non-traversable 
	object.
	\par
	The authors in \cite{Pfaff} classify the cells of \term{elevation maps} into 
	parts of terrain seen from above, vertical objects,	overhanging objects (such as 
	branches of trees or bridges) and traversable areas. That way, they manage to 
	only keep the height values for the lowest surface in each cell. As a result, 
	the area under the bridge, in the previous example, will appear as a traversable 
	surface.
	\\
	
	Yet, another approach is kind of a mixture of the previous ones. The autonomous 
	vehicle has also to decide for itself the \term{traversability} of the terrain 
	around it. But it has no a priori knowledge of the kind of terrain it will 
	traverse, so it must learn as it goes along by observing the geometry and 
	appearance of the terrain. That is both proprioceptive and exteroceptive sensory 
	data processing (more about them can be found in \cite{Papadakis}). 
	\par
	Shneier et al. follow an approach such as the above. They use a local 
	\term{occupancy grid} map that scrolls under the vehicle as the vehicle moves,
	and cells that scroll off the end of the map are forgotten \cite{Shneier}. They 
	do not use a global map and the previous known information is forgotten once the 
	robot moves away from that location. Considering distance above or below the 
	ground, color, texture, and contrast, they estimate each cell’s 
	\term{traversability}. This estimation of the cost of traversing regions is used 
	to generate models of terrain in order for the robot to learn from its own 
	experience.
	\\
	
	
	
	
	\sout{In order to create the 2d grid map mentioned above, the authors use two 
	strategies to learn a classifier from this kind of 
	training data. The former estimates the frequencies of observed	features in the 
	classical way. Since the data is only incompletely labeled and contains no 
	negative labeled samples, it calculates an estimate for the negative 
	frequencies from the previous estimate of the positive frequencies and the prior. The 
	latter, on the other hand, uses the training data in a way to create a classical 
	learning problem with full labeled data. It estimates the distribution for a 
	feature to get a label (always positive) during the training, therefore it is 
	known for each feature whether it got a label or not.}
	
	\cite{Suger}: collect partially labeled training data
	\\
	
	\sout{A forward-looking image alone may be insufficient for planning and navigation
	\cite{Kweon}. Robots operating in rough terrain may require knowledge of 
	terrain that has been observed but is currently out of the sensor field of
	view such as terrain under and behind the robot.}
	
	This line of research starts with Papadakis (2013) who published a 
	survey done in \term{traversability analysis} methods for unmanned ground vehicles 
	\cite{Papadakis}. 
	The attention had most often been focused on methodologies that access the 
	\term{traversability} characteristics before actually driving over the respective 
	region.
	This survey states that historically, most commonly, \term{traversability} analysis is treated 
	as a binary classification problem, i.e. distinguishing traversable from 
	non-traversable terrain \cite{Suger, Hirose, Wigness}. 
	But later on, the need for finer classification was recognized that either assigned 
	a continuous \term{traversability} score or classified the terrain into the various classes 
	that were commonly encountered within a particular application.
	That does not mean that binary terrain classification should be viewed as redundant
	or trivial, because the computational complexity of analysis increases together 
	with terrain complexity.
	It also declares that one of the most popular and extensively used approaches 
	to measure \term{traversability} are based on grid 
	maps. More concrete, they are based on the analysis of 2d elevation maps, 
	where 3d information is represented in 2d maps \cite{Suger}.
	\\
	
	\section{Data collection methods}
	\label{sec:bg:data}
	
	In environments where the ground is not flat or contains obstacles that are 
	not purely vertical, the basic approach of classifying based on the observed 
	obstacles from \acronym{2d} laser scanners can not be safely used anymore. 
	In these cases, \acronym{3d} range data, e.g. \acronym{3d} \acronym{lidar} 
	data, is necessary \cite{Suger, Lalonde}. \acronym{lidar} (called \term{ladar} 
	in \cite{Lalonde, Shneier}) is an acronym used for \term{light detection and 
	ranging}). It is a surveying method that measures distance to a target by 
	illuminating the target with pulsed laser light and measuring the reflected 
	pulses with a sensor. Differences in laser return times and wavelengths that 
	can then be used to make digital \acronym{3d} representations of the target.
	\\
	
	Others do not use geometric data, but instead concentrate on visual data, 
	\term{appearance-based} methodologies as they are called from \cite{Papadakis}. 
	Instead of using \acronym{lidar} \cite{Lalonde, Suger}, they use different 
	sensors, like onboard and off-the-shelf fisheye camera \cite{Hirose}, to 
	estimate whether a physical space is traversable or not. This kind of 
	approaches are mainly focused on obstacle detection and avoidance, and less 
	on \term{traversability} estimation for obstacles that may seem untraversable 
	while in fact can be easily driven over by a robot, like tall grass.
	\\
	
	
	
	
	
	Kim et al. \cite{Kim} developed a method 
	that is based on autonomous training data collection which, exploits the 
	robot’s experience in navigating its environment to train classifiers without 
	human intervention. It is broadly applicable to any environment in which 
	the robot can be safely driven as it uses the interaction between the vehicle
	and its environment to ground the problem of \term{traversability} classification.
	
	The main idea is that image data  obtained in the past is associated with 
	\term{traversability} labels obtained in the  present. The learning process produces a 
	classifier which makes \term{traversability}  predictions for new terrain regions. 
	Successes and failures of the navigation provide positive and negative 
	\term{traversability} labels for cells in a grid-based representation of the terrain surrounding 
	the vehicle.
	
	\textit{The robot is equipped with two pairs of stereo vision cameras which 
	collect visual and geometric data from the environment, and a bumper switch
	at the front of the vehicle that is used along with motor current sensors to 
	signal events such as \example{stuck} and \example{slip}.
	\\
	For starters, the robot images the terrain in front of it and stores the 
	resulting image patches in a data pool. Each image patch is an observation 
	of a single cell in a grid-based terrain map. Initially all of this data is 
	unlabeled, because the robot has not yet interacted with the terrain, and its 
	\term{traversability} is unknown. 
	\\
	Then the robot attempts to drive over the terrain that it previously 
	observed, thus discovering the \term{traversability} properties of the environment. 
	Cells under the robot footprint that can be driven over are traversable and 
	therefore yield positive training examples, while those that hinder the robot’s 
	motion are non-traversable	and result in negative examples.}
	
	The authors also propose an on-line learning method in order to exploit 
	newly-acquired training data in making \term{traversability} predictions about 
	unknown terrain. That way the learned \term{traversability} concepts are 
	incrementally updated with new data only. That comes with the advantage that the 
	updated classifier is immediately available for navigation and that the 
	memory requirements for learning are reduced, compared to off-line methods.
	\\
	
	
	
	Another way to generate and collect training data is to obtain them through 
	a human operator that drives a safe trajectory that is similar to the 
	environment where the robot should later be able to reliable operate in. 
	This process for training data generation has the advantage that it is fairly 
	easy to execute.
	\par 
	From this training trajectory, \cite{Suger} label the cells of the map that 
	intersect with the projection of the footprint of the robot as positive 
	examples. This has the drawback that the labeled data are only positive 
	examples, leaving tons of unlabeled data to learn from.
	\par 
	In a variation of this, optimal trajectory examples are collected \cite{Wigness} 
	in order to be used from a reward function and train the robot.
	
	\section{Goals of operation}
	\label{sec:bg:goals}
	
	A natural thing would be to let the robot learn about the \term{traversability} 
	of the environment, while another perspective would be to concentrate on more 
	preservative situations, such as go or no-go \cite{Hirose}. Even though the 
	former method allows the robot to autonomously learn a model of the environment, 
	the trial and error part of it involves a high risk to damage the robot. The 
	latter, on the other hand, has as main priority to prevent robots from 
	colliding with objects, injuring people, getting stuck in constrained spaces, 
	or falling over an edge. A third approach would be to let the autonomous vehicle 
	navigate from a defined start point to a fixed goal	point \cite{Shneier}. That 
	way the robot has to build a model of the world around it and plan a path from 
	the start to the goal. 
	\sout{Early runs enable the robot to learn which regions to 
	avoid and which to seek out, so that later on it can determine the most efficient 
	path.}
	\\
	
	\section{Prototype implementations / reference implementation}
	\label{sec:bg:code}
	
	URLs and comments about the work above that will actually be used as 
	the experimental basis
	\\
		
	\section{Conclusions}
	\label{sec:bg:concl}
	
	What is missing in order to be able to achieve the promise in Chap 1
	
	
	\chapter{Core foreground}
	\label{sec:fg}
	
	\chapter{Experimental Validation and Comparison}
	\label{sec:exp}
	
	\chapter{Conclusions and Future Work}
	\label{sec:concl}
	
	\renewcommand{\bibname}{References}
	\bibliography{ref}
	\bibliographystyle{ieeetr}
\end{document}